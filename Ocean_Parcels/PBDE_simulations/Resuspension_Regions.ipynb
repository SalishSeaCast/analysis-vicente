{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec6aecd",
   "metadata": {},
   "source": [
    "# Regions and Resuspension Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean.cm as cm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.colors import ListedColormap\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/vvalenzuela/MOAD/Ocean_Parcels/results/Simulations_runs/PBDE_particles_for_0112022_run_365_days_full_kernels_tau_0_01_ratio_0_1_sv_5_AD_0_052.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66eedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Regions_functions_V2\n",
    "from Regions_functions_V2 import plot_vertical_concentration_state_profiles, plot_vertical_total_state_profiles, plot_vertical_state_status, interpolate_volume_profile\n",
    "polygon_dict = Regions_functions_V2.polygon_definition(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_water, regions_sedimented = Regions_functions_V2.status_states_regions_map(polygon_dict)\n",
    "####### regions ########\n",
    "# written like N1_sedimented_lon, N1_sedimented_lat \n",
    "#\n",
    "region_names = ['N1', 'N2', 'N3', 'C1', 'S1', 'SP', 'HW1', 'F1', 'S2', 'H1', 'J1']\n",
    "\n",
    "water_regions_lon = [regions_water[region]['lon'] for region in region_names]\n",
    "water_regions_lat = [regions_water[region]['lat'] for region in region_names]\n",
    "water_regions_depth = [regions_water[region]['depth'] for region in region_names]\n",
    "\n",
    "sedimented_regions_lon = [regions_sedimented[region]['lon'] for region in region_names]\n",
    "sedimented_regions_lat = [regions_sedimented[region]['lat'] for region in region_names]\n",
    "sedimented_regions_depth = [regions_sedimented[region]['depth'] for region in region_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(filename, engine='zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf75055",
   "metadata": {},
   "source": [
    "Lets see for 1 day cycle    :o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361193d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_day = data.isel(obs = np.arange(1216, 1460)).time[0,:].values\n",
    "data_day =  data.isel(obs = np.arange(1216, 1460))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_day_water = data_day.where((data_day.status < 10) & (data_day.status > 0))\n",
    "data_day_sediment = data_day.where(data_day.status > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4128a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = pd.to_datetime(times_day[0]).to_pydatetime()\n",
    "end = pd.to_datetime(times_day[-1]).to_pydatetime()\n",
    "t_len = (end - begin).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; import glob; from datetime import timedelta\n",
    "def date_files(date, path, prefix_type= 'grid_T.nc'):\n",
    "    folder = date.strftime(\"%d%b%y\").lower()\n",
    "    prefix = os.path.join(path, folder + f'/SalishSea_1h_{date.strftime(\"%Y%m%d\").lower()}_{date.strftime(\"%Y%m%d\").lower()}_{prefix_type}*')\n",
    "    file_name = glob.glob(prefix) \n",
    "    return file_name\n",
    "#\n",
    "def get_timestamps(start,length):\n",
    "    timestamps=[]\n",
    "    duration = timedelta(days=length)\n",
    "    for day in range(duration.days):\n",
    "        timestamps.append([start + timedelta(days=day)])\n",
    "    return timestamps\n",
    "#\n",
    "dates = get_timestamps(begin,t_len)\n",
    "hourly_dates = pd.date_range(start=begin, end=end, freq='H')[:-1]\n",
    "#\n",
    "path_days_h = '/results2/SalishSea/nowcast-green.202111/'\n",
    "#\n",
    "files_U = []\n",
    "files_V = []\n",
    "files_e3t = []\n",
    "for i in range(t_len):\n",
    "    files_U.append(date_files(dates[i][0],path_days_h, prefix_type = 'grid_U.nc'))\n",
    "    files_V.append(date_files(dates[i][0],path_days_h, prefix_type = 'grid_V.nc'))\n",
    "    files_e3t.append(date_files(dates[i][0],path_days_h, prefix_type = 'grid_T.nc'))\n",
    "#\n",
    "path_bat = '/ocean/vvalenzuela/MOAD/grid2/mesh_mask202108_TDV.nc'\n",
    "bat_file = xr.open_dataset(path_bat)\n",
    "mbathy = bat_file['mbathy'][0]\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c985e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "jjii = xr.open_dataset('/ocean/vvalenzuela/MOAD/grid/grid_from_lat_lon_mask999.nc')\n",
    "def finder(lati,loni):\n",
    "    j = [jjii.jj.sel(lats=lati, lons=loni, method='nearest').item()][0]\n",
    "    i = [jjii.ii.sel(lats=lati, lons=loni, method='nearest').item()][0]\n",
    "    return j,i\n",
    "#################################################################################################    \n",
    "a, b = finder(49.2,-123.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71255fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_U = [f[0] for f in files_U]\n",
    "filepaths_V = [f[0] for f in files_V]\n",
    "filepaths_e3t = [f[0] for f in files_e3t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_idx = mbathy[a,b].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b46a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_vels = []\n",
    "for file in filepaths_U:\n",
    "    datito_u = xr.open_dataset(file)['vozocrtx'].isel(depthu=depth_idx - 1, y=a, x=b)\n",
    "    U_vels.append(datito_u)\n",
    "#\n",
    "V_vels = []\n",
    "for file in filepaths_V:\n",
    "    datito_v = xr.open_dataset(file)['vomecrty'].isel(depthv=depth_idx - 1, y=a, x=b)\n",
    "    V_vels.append(datito_v)\n",
    "#\n",
    "e3ts = []\n",
    "for file in filepaths_e3t:\n",
    "    datito_e3t = xr.open_dataset(file)['e3t'].isel(deptht=depth_idx - 1, y=a, x=b)\n",
    "    e3ts.append(datito_e3t)  \n",
    "#\n",
    "sshs = []\n",
    "for file in filepaths_e3t:\n",
    "    datito_ssh = xr.open_dataset(file)['sossheig'].isel(y=a, x=b)\n",
    "    sshs.append(datito_ssh)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Calculations_Functions import proportions_from_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = proportions_from_filename(filename = filename)\n",
    "#\n",
    "water, sediment =  proportions['Sewage Water'] + proportions['Colloidal Water'] + proportions['Marine Water'] , proportions['Sewage Sediment'] + proportions['Colloidal Sediment'] + proportions['Marine Sediment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_velocity = xr.concat(U_vels, dim='time_counter')\n",
    "V_velocity = xr.concat(V_vels, dim='time_counter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "e3t_values = xr.concat(e3ts, dim='time_counter')\n",
    "ssh_values = xr.concat(sshs, dim='time_counter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f9102",
   "metadata": {},
   "source": [
    "$$u^{*} = \\frac{U \\cdot k}{ln(\\frac{z}{z_{*}})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = e3t_values / 2\n",
    "z_star = 0.07\n",
    "k = 0.42\n",
    "#\n",
    "vel_horizontal = np.sqrt(U_velocity**2 + V_velocity**2)\n",
    "# Final u* calculation\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    u_star = (vel_horizontal * k) / np.log(z / z_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "#\n",
    "spline_ustar = UnivariateSpline(range(len(u_star)), u_star.values, s=.006)\n",
    "smoothed_values_ustar = spline_ustar(range(len(u_star)))\n",
    "#\n",
    "smoothed_ustar = pd.Series(smoothed_values_ustar, index=U_velocity.time_counter)\n",
    "#\n",
    "spline_ssh = UnivariateSpline(range(len(ssh_values)), ssh_values.values, s=700)\n",
    "smoothed_values_ssh = spline_ssh(range(len(ssh_values)))\n",
    "#\n",
    "smoothed_ssh = pd.Series(smoothed_values_ssh, index=ssh_values.time_counter)\n",
    "#\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "#\n",
    "fig, ax = plt.subplots(2,1,figsize = (18,8), height_ratios=[1, .5], sharex=True)\n",
    "#\n",
    "ax[1].plot(smoothed_ssh.index, ssh_values, 'g', alpha = .2)\n",
    "ax[1].plot(smoothed_ssh, 'g')\n",
    "#\n",
    "ax[1].grid(alpha = .7)\n",
    "ax[1].set_ylabel('SSH [m]')\n",
    "#\n",
    "ax[0].plot(smoothed_ustar.index, u_star, 'k', alpha = .2, label = r'Raw $\\tau$')\n",
    "ax[0].plot(smoothed_ustar, 'k', alpha = 1, label = r'Smoothed $\\tau$')\n",
    "#\n",
    "#ax.vlines(x = times_day[t], ymin = 0, ymax = .015, color = 'g')\n",
    "#ax.hlines(y=0.01, xmin = U_velocity['time_counter'][0], xmax = U_velocity['time_counter'][-1], color = 'g', linestyle = '--')\n",
    "ax[0].set_ylabel(r'Bottom Stress due to Currents ($\\tau$)')\n",
    "ax[0].legend(loc = 'upper left')\n",
    "ax[0].grid(alpha = .7)\n",
    "#\n",
    "axis = ax[0].twinx()\n",
    "axis.plot(water, 'b', label = 'Water Column')\n",
    "axis.plot(sediment, 'r', label = 'Sediment')\n",
    "axis.set_xlim([times_day[0], times_day[-1]])\n",
    "axis.legend(loc = 'upper right')\n",
    "axis.set_ylabel('Proportion (%)')\n",
    "#\n",
    "ax[0].set_ylim([-0.001, 0.016])\n",
    "axis.set_ylim([-5, 80])\n",
    "#\n",
    "plt.subplots_adjust(hspace=0, top=0.97, bottom=0.07, left=0.07, right=0.93)\n",
    "#\n",
    "#\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65817cce",
   "metadata": {},
   "source": [
    "Can we know when resuspension happens in the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = data.status.values\n",
    "#\n",
    "status_now = status[:, :-1]     # current timestep\n",
    "status_next = status[:, 1:]     # next timestep\n",
    "#\n",
    "all_ss_to_c = (status_now == 11) & (status_next == 2)\n",
    "all_cs_to_c = (status_now == 12) & (status_next == 2)\n",
    "all_ms_to_c = (status_now == 13) & (status_next == 2)\n",
    "\n",
    "all_ss_to_m = (status_now == 11) & (status_next == 3)\n",
    "all_cs_to_m = (status_now == 12) & (status_next == 3)\n",
    "all_ms_to_m = (status_now == 13) & (status_next == 3)\n",
    "\n",
    "total_sediment_transitions = (\n",
    "    np.count_nonzero(all_ss_to_c) +\n",
    "    np.count_nonzero(all_cs_to_c) +\n",
    "    np.count_nonzero(all_ms_to_c) +\n",
    "    np.count_nonzero(all_ss_to_m) +\n",
    "    np.count_nonzero(all_cs_to_m) +\n",
    "    np.count_nonzero(all_ms_to_m)\n",
    ")\n",
    "\n",
    "# Percentage of sediment transitions\n",
    "print(np.count_nonzero(all_ss_to_c) / total_sediment_transitions * 100, '% ss_to_c')\n",
    "print(np.count_nonzero(all_cs_to_c) / total_sediment_transitions * 100, '% cs_to_c')\n",
    "print(np.count_nonzero(all_ms_to_c) / total_sediment_transitions * 100, '% ms_to_c')\n",
    "print(np.count_nonzero(all_ss_to_m) / total_sediment_transitions * 100, '% ss_to_m')\n",
    "print(np.count_nonzero(all_cs_to_m) / total_sediment_transitions * 100, '% cs_to_m')\n",
    "print(np.count_nonzero(all_ms_to_m) / total_sediment_transitions * 100, '% ms_to_m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434029f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_res = ['S. S. to C.', 'C. S. to C.', 'M. S. to C.', 'S. S. to M.', 'S. C. to M.', 'S. M to M.']\n",
    "per_res = [np.count_nonzero(all_ss_to_c) / total_sediment_transitions * 100, \n",
    "           np.count_nonzero(all_cs_to_c) / total_sediment_transitions * 100,\n",
    "           np.count_nonzero(all_ms_to_c) / total_sediment_transitions * 100,\n",
    "           np.count_nonzero(all_ss_to_m) / total_sediment_transitions * 100,\n",
    "           np.count_nonzero(all_cs_to_m) / total_sediment_transitions * 100,\n",
    "           np.count_nonzero(all_ms_to_m) / total_sediment_transitions * 100]\n",
    "colors_res = ['k', 'r', 'g', 'k', 'r', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b604e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = data.z.values  \n",
    "\n",
    "z_now = z[:, :-1] \n",
    "\n",
    "\n",
    "depths_ss_to_c = z_now[all_ss_to_c]\n",
    "depths_cs_to_c = z_now[all_cs_to_c]\n",
    "depths_ms_to_c = z_now[all_ms_to_c]\n",
    "\n",
    "depths_ss_to_m = z_now[all_ss_to_m]\n",
    "depths_cs_to_m = z_now[all_cs_to_m]\n",
    "depths_ms_to_m = z_now[all_ms_to_m]\n",
    "\n",
    "#\n",
    "depth_data = [\n",
    "    depths_ss_to_c, depths_cs_to_c, depths_ms_to_c,\n",
    "    depths_ss_to_m, depths_cs_to_m, depths_ms_to_m\n",
    "]\n",
    "means = []\n",
    "medians = []\n",
    "mins = []\n",
    "maxs = []\n",
    "counts = []\n",
    "\n",
    "for label, arr in zip(labels_res, depth_data):\n",
    "    if arr.size > 0:\n",
    "        means.append(arr.mean())\n",
    "        medians.append(np.median(arr))\n",
    "        mins.append(arr.min())\n",
    "        maxs.append(arr.max())\n",
    "        counts.append(arr.size)\n",
    "        print(f'{label}: mean={arr.mean():.2f}, median={np.median(arr):.2f}, min={arr.min():.2f}, max={arr.max():.2f}, n={arr.size}')\n",
    "    else:\n",
    "        means.append(np.nan)\n",
    "        medians.append(np.nan)\n",
    "        mins.append(np.nan)\n",
    "        maxs.append(np.nan)\n",
    "        counts.append(0)\n",
    "        print(f'{label}: No transitions')\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4131206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "#\n",
    "fig, ax = plt.subplots(2,1,figsize=(20, 12), height_ratios=[1, .8], sharex=True)\n",
    "bars1 = ax[0].bar(labels_res[:3], per_res[:3], color = colors_res[:3], hatch = '//', alpha = .7, label = 'To Colloidal from Sediment')\n",
    "bars2 = ax[0].bar(labels_res[3:], per_res[3:], color = colors_res[3:], alpha = .7, label = 'To M. Particle from Sediment')\n",
    "\n",
    "\n",
    "for bar, value in zip(bars1, per_res[:3]):\n",
    "    ax[0].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.5, \n",
    "        f'{value:.2f}%',\n",
    "        ha='center', va='bottom', fontsize=16, fontweight='bold'\n",
    "    )\n",
    "    #\n",
    "for bar, value in zip(bars2, per_res[3:]):\n",
    "    ax[0].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.5, \n",
    "        f'{value:.2f}%',\n",
    "        ha='center', va='bottom', fontsize=16, fontweight='bold'\n",
    "    )\n",
    "\n",
    "ax[0].set_title('Resuspension Transitions vs Total Number of Sediment Resuspension Transitions', fontsize=22)\n",
    "ax[0].set_ylabel('Percentage from \\n Total Transtions (%)', fontsize=14)\n",
    "ax[0].set_ylim(0, max(per_res) * 1.2) \n",
    "ax[0].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "ax[0].legend()\n",
    "######\n",
    "ax[1].plot(labels_res, means, '-ok', label = 'Mean')\n",
    "ax[1].plot(labels_res, medians, '-db', label = 'Median')\n",
    "ax[1].plot(labels_res, mins, '--sm', label = 'Min')\n",
    "ax[1].plot(labels_res, maxs, '--sc', label = 'Max')\n",
    "ax[1].invert_yaxis()\n",
    "ax[1].grid()\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('Resuspension transition Depth [m]')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
